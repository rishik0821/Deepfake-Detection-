{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1SUJQ2PUBrUIQrfFb7FlVJzQK3PLUW3Ke","authorship_tag":"ABX9TyM67QqzxHg3rJsjtQMJ3nIQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JF7M3QyLczph"},"outputs":[],"source":["  # Import required libraries\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import models, transforms\n","from PIL import Image\n","import os\n","import numpy as np"]},{"cell_type":"code","source":["# Check if GPU is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"],"metadata":{"id":"Wuykp3J3dSf3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Define image transformations\n","transform = transforms.Compose([\n","    transforms.RandomResizedCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])"],"metadata":{"id":"PaTmEqfgdXdM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 2: Define Custom Dataset\n","class DeepfakeImageDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.classes = {'Real': 0, 'Fake': 1}\n","        self.data = []\n","\n","        for label in self.classes:\n","            class_dir = os.path.join(root_dir, label)\n","            for img_name in os.listdir(class_dir):\n","                img_path = os.path.join(class_dir, img_name)\n","                self.data.append((img_path, self.classes[label]))\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img_path, label = self.data[idx]\n","        image = Image.open(img_path).convert('RGB')\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label"],"metadata":{"id":"zhiG699ddZ_4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Install required packages\n","!pip install torch torchvision seaborn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3yTdv80nd1Ck","executionInfo":{"status":"ok","timestamp":1730115126467,"user_tz":-330,"elapsed":3504,"user":{"displayName":"Bcuber Mem","userId":"09286632576840638536"}},"outputId":"4f369f01-03eb-4c68-e520-76bddc7f78bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n","Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.2.2)\n","Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wdCaC3OOd6d6","executionInfo":{"status":"ok","timestamp":1730115158808,"user_tz":-330,"elapsed":25622,"user":{"displayName":"Bcuber Mem","userId":"09286632576840638536"}},"outputId":"94daffd4-b852-4dd0-993d-1c2e23bb9b22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["\n","train_dataset = DeepfakeImageDataset('/content/drive/MyDrive/Deep_learning/TrimDataset/Dataset/Train', transform=transform)\n","val_dataset = DeepfakeImageDataset('/content/drive/MyDrive/Deep_learning/TrimDataset/Dataset/Validation', transform=transform)\n","test_dataset = DeepfakeImageDataset('/content/drive/MyDrive/Deep_learning/TrimDataset/Dataset/Test', transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"],"metadata":{"id":"bDBGzvn9deAN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Define ResNeXt Model\n","class ResNeXtClassifier(nn.Module):\n","    def __init__(self, dropout_rate=0.5):\n","        super(ResNeXtClassifier, self).__init__()\n","        self.resnext = models.resnext50_32x4d(pretrained=True)\n","        num_ftrs = self.resnext.fc.in_features\n","        self.resnext.fc = nn.Sequential(\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(num_ftrs, 2)  # Adjust the final layer to output 2 classes\n","        )\n","\n","    def forward(self, x):\n","        return self.resnext(x)\n","\n","model = ResNeXtClassifier(dropout_rate=0.6).to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v7uhXJW_dhcd","executionInfo":{"status":"ok","timestamp":1730115205088,"user_tz":-330,"elapsed":2059,"user":{"displayName":"Bcuber Mem","userId":"09286632576840638536"}},"outputId":"11dd676f-f101-4414-9bce-81a5ef63bfa2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt50_32X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt50_32X4D_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n","100%|██████████| 95.8M/95.8M [00:00<00:00, 136MB/s]\n"]}]},{"cell_type":"code","source":["# Step 5: Define Loss Function, Optimizer, and Early Stopping Parameters\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n","num_epochs = 10\n","patience = 3  # For early stopping\n","best_val_loss = np.inf\n","early_stop_counter = 0"],"metadata":{"id":"tj6yQWhPdpSo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training Loop with Early Stopping\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss, train_correct = 0, 0\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        train_correct += predicted.eq(labels).sum().item()\n","\n","    train_accuracy = train_correct / len(train_dataset)\n","    train_loss /= len(train_loader)\n","\n","    # Validation phase\n","    model.eval()\n","    val_loss, val_correct = 0, 0\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            val_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            val_correct += predicted.eq(labels).sum().item()\n","\n","    val_accuracy = val_correct / len(val_dataset)\n","    val_loss /= len(val_loader)\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n","          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n","          f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n","\n","    # Early Stopping\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        torch.save(model.state_dict(), '/content/best_resnet_model.pth')\n","        early_stop_counter = 0\n","    else:\n","        early_stop_counter += 1\n","        if early_stop_counter >= patience:\n","            print(\"Early stopping triggered.\")\n","            break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lOUZjIUDevfP","executionInfo":{"status":"ok","timestamp":1730027039782,"user_tz":-330,"elapsed":2145663,"user":{"displayName":"Bcuber Mem","userId":"09286632576840638536"}},"outputId":"3886dbae-9764-41ff-c912-d6148e19fb9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.2587, Train Accuracy: 0.8796, Val Loss: 0.1293, Val Accuracy: 0.9494\n","Epoch [2/10], Train Loss: 0.1354, Train Accuracy: 0.9469, Val Loss: 0.2214, Val Accuracy: 0.9091\n","Epoch [3/10], Train Loss: 0.1155, Train Accuracy: 0.9584, Val Loss: 0.2780, Val Accuracy: 0.9033\n","Epoch [4/10], Train Loss: 0.1011, Train Accuracy: 0.9613, Val Loss: 0.1672, Val Accuracy: 0.9369\n","Early stopping triggered.\n"]}]},{"cell_type":"code","source":["pip install torch torchvision torchaudio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pzHkHwyEs-AO","executionInfo":{"status":"ok","timestamp":1730103643636,"user_tz":-330,"elapsed":4821,"user":{"displayName":"Bcuber Mem","userId":"09286632576840638536"}},"outputId":"431a017b-a11d-4275-e439-af1fd3456f65"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), '/content/drive/MyDrive/DL/best_resnext_model.pth')\n"],"metadata":{"id":"PSzBZ9F4sl2q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model, '/content/drive/MyDrive/DL/entire_resnext_model.pth')\n"],"metadata":{"id":"AjbbrgnrtVMg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load('/content/drive/MyDrive/DL/best_resnext_model.pth'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FDnFtKoFdsKM","executionInfo":{"status":"ok","timestamp":1730115238445,"user_tz":-330,"elapsed":5539,"user":{"displayName":"Bcuber Mem","userId":"09286632576840638536"}},"outputId":"9b2aa2d9-2567-4f7c-883f-ac0a897c8475"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-10-f5d5fed428ed>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load('/content/drive/MyDrive/DL/best_resnext_model.pth'))\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["from PIL import Image\n","import torch\n","\n","def test_image(image_path, model):\n","    # Load and preprocess the image\n","    image = Image.open(image_path).convert('RGB')\n","    image = transform(image).unsqueeze(0).to(device)  # Add batch dimension\n","\n","    # Get prediction\n","    with torch.no_grad():\n","        output = model(image)\n","        _, predicted = torch.max(output, 1)\n","\n","    # Interpret the result\n","    class_labels = {0: 'Real', 1: 'Fake'}\n","    print(f\"Predicted: {class_labels[predicted.item()]}\")\n","\n","# Example usage with your specific image path\n","test_image('/content/drive/MyDrive/Deep_learning/TrimDataset/Dataset/Validation/Fake/fake_2.jpg', model)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HJSGlWdgvMvx","executionInfo":{"status":"ok","timestamp":1730115255338,"user_tz":-330,"elapsed":706,"user":{"displayName":"Bcuber Mem","userId":"09286632576840638536"}},"outputId":"1073428f-e3e2-46a5-ea68-3be60985ce40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted: Fake\n"]}]}]}