{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOZDUXxChYrUtztEXSinQlV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YYPwIipAC5a8","executionInfo":{"status":"ok","timestamp":1739701589860,"user_tz":-330,"elapsed":30613,"user":{"displayName":"Bcuber Mem","userId":"09286632576840638536"}},"outputId":"acefad36-533d-4a05-8b5a-a4be56875b50"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import models, transforms\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","from sklearn.utils.class_weight import compute_class_weight\n","import numpy as np\n"],"metadata":{"id":"10JaQRxADSWl","executionInfo":{"status":"ok","timestamp":1739701605305,"user_tz":-330,"elapsed":10130,"user":{"displayName":"Bcuber Mem","userId":"09286632576840638536"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Set up device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Data transformations for image processing\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","# Custom Dataset Class for Deepfake Images\n","class DeepfakeImageDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.classes = {'Real': 0, 'Fake': 1}\n","        self.data = []\n","\n","        for label in self.classes:\n","            class_dir = os.path.join(root_dir, label)\n","            for img_name in os.listdir(class_dir):\n","                img_path = os.path.join(class_dir, img_name)\n","                self.data.append((img_path, self.classes[label]))\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img_path, label = self.data[idx]\n","        image = Image.open(img_path).convert('RGB')\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label\n"],"metadata":{"id":"Bc4dcm7ODZgF","executionInfo":{"status":"ok","timestamp":1739701639029,"user_tz":-330,"elapsed":437,"user":{"displayName":"Bcuber Mem","userId":"09286632576840638536"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Define dataset directories (adjust these paths)\n","train_dir = '/content/drive/MyDrive/Deep_learning/TrimDataset/Dataset/Train'\n","val_dir = '/content/drive/MyDrive/Deep_learning/TrimDataset/Dataset/Validation'\n","test_dir = '/content/drive/MyDrive/Deep_learning/TrimDataset/Dataset/Test'\n","\n","# Load datasets\n","train_dataset = DeepfakeImageDataset(train_dir, transform=transform)\n","val_dataset = DeepfakeImageDataset(val_dir, transform=transform)\n","test_dataset = DeepfakeImageDataset(test_dir, transform=transform)\n","\n","# DataLoader for batch processing\n","test_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","train_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n"],"metadata":{"id":"AyhKy3uvEejL","executionInfo":{"status":"ok","timestamp":1739701666271,"user_tz":-330,"elapsed":23802,"user":{"displayName":"Bcuber Mem","userId":"09286632576840638536"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# ResNet Feature Extractor\n","class ResNetFeatureExtractor(nn.Module):\n","    def __init__(self):\n","        super(ResNetFeatureExtractor, self).__init__()\n","        self.resnet = models.resnet50(pretrained=True)\n","        self.resnet.fc = nn.Identity()  # Remove final classification layer\n","\n","    def forward(self, x):\n","        return self.resnet(x)\n","\n","\n","# LSTM Classifier Model\n","class LSTMClassifier(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout=0.5):\n","        super(LSTMClassifier, self).__init__()\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(2, x.size(0), 128).to(device)  # Initial hidden state\n","        c0 = torch.zeros(2, x.size(0), 128).to(device)  # Initial cell state\n","        out, _ = self.lstm(x, (h0, c0))\n","        out = self.fc(out[:, -1, :])  # Output from last LSTM step\n","        return out\n","\n"],"metadata":{"id":"CNDjudJ4Eh7-","executionInfo":{"status":"ok","timestamp":1739701681665,"user_tz":-330,"elapsed":495,"user":{"displayName":"Bcuber Mem","userId":"09286632576840638536"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Initialize models\n","feature_extractor = ResNetFeatureExtractor().to(device)\n","lstm_model = LSTMClassifier(input_size=2048, hidden_size=128, num_layers=2, num_classes=2).to(device)\n","\n","# Class weights based on real/fake distribution\n","y_train = [label for _, label in train_dataset]\n","class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n","class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)  # Class weights added\n","optimizer = torch.optim.Adam(lstm_model.parameters(), lr=1e-4)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1bYWFef5EnS_","executionInfo":{"status":"ok","timestamp":1739702470492,"user_tz":-330,"elapsed":784800,"user":{"displayName":"Bcuber Mem","userId":"09286632576840638536"}},"outputId":"bc028d84-321c-422a-fcbd-2ea9c9cce67e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100%|██████████| 97.8M/97.8M [00:00<00:00, 146MB/s]\n"]}]},{"cell_type":"code","source":["# Training settings\n","epochs = 10\n","patience = 3  # Early stopping patience\n","best_test_acc = 0  # Track best test accuracy for model saving\n","trigger_times = 0\n","\n","# Custom threshold for classification\n","threshold = 0.5\n","\n","for epoch in range(epochs):\n","    # Training phase\n","    lstm_model.train()\n","    total_loss, total_correct = 0, 0\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        # Extract features with ResNet\n","        with torch.no_grad():  # Freeze ResNet weights\n","            features = feature_extractor(images).unsqueeze(1)  # (batch, seq_len, features)\n","\n","        # LSTM classification\n","        outputs = lstm_model(features)\n","        loss = criterion(outputs, labels)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total_correct += predicted.eq(labels).sum().item()\n","\n","    train_accuracy = total_correct / len(train_dataset)\n","    train_loss = total_loss / len(train_loader)\n","\n","    # Testing phase at the end of each epoch\n","    lstm_model.eval()\n","    test_correct = 0\n","    test_total = 0\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","\n","            # Extract features with ResNet\n","            features = feature_extractor(images).unsqueeze(1)\n","\n","            # LSTM model prediction\n","            outputs = lstm_model(features)\n","\n","            # Apply threshold to classify as real or fake\n","            probs = torch.softmax(outputs, dim=1)\n","            predicted = (probs[:, 1] >= threshold).long()\n","\n","            # Count correct predictions\n","            test_correct += predicted.eq(labels).sum().item()\n","            test_total += labels.size(0)\n","\n","    test_accuracy = test_correct / test_total\n","\n","\n","\n","    print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, \"\n","          f\"Test Acc: {test_accuracy:.4f}\")\n","\n","    # Early stopping check based on test accuracy\n","    if test_accuracy > best_test_acc:\n","        best_test_acc = test_accuracy\n","        trigger_times = 0\n","        torch.save(lstm_model.state_dict(), '/content/drive/MyDrive/DL/best_lstm_model.pth')  # Save the best model\n","    else:\n","        trigger_times += 1\n","        if trigger_times >= patience:\n","            print(\"Early stopping triggered.\")\n","            break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5oZKDxJvEpuC","outputId":"465774dc-754a-4926-8019-a0ceb73d842b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.3083, Train Acc: 0.8749, Test Acc: 0.5141\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"KOF_d-gXEro7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the trained LSTM model's state dictionary\n","torch.save(lstm_model.state_dict(), \"/content/drive/MyDrive/DL/FinalLSTM_model.pth\")\n"],"metadata":{"id":"84TJNCk0EuN4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the trained model if you saved it\n","lstm_model.load_state_dict(torch.load('/content/drive/MyDrive/DL/FinalLSTM_model.pth'))\n","lstm_model.eval()  # Set model to evaluation mode\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ptlj9SHX-GG6","executionInfo":{"status":"ok","timestamp":1730049277271,"user_tz":-330,"elapsed":427,"user":{"displayName":"Bcuber Mem","userId":"09286632576840638536"}},"outputId":"43a818de-77f2-4e63-8953-d71027abd740"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-12-476c61195496>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  lstm_model.load_state_dict(torch.load('/content/drive/MyDrive/DL/FinalLSTM_model.pth'))\n"]},{"output_type":"execute_result","data":{"text/plain":["LSTMClassifier(\n","  (lstm): LSTM(2048, 128, num_layers=2, batch_first=True, dropout=0.5)\n","  (fc): Linear(in_features=128, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# Transformation pipeline for inference\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n"],"metadata":{"id":"csOklIhx-Q1C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the trained models\n","feature_extractor = ResNetFeatureExtractor().to(device)\n","feature_extractor.eval()  # Set to evaluation mode\n","\n","lstm_model = LSTMClassifier(input_size=2048, hidden_size=128, num_layers=2, num_classes=2).to(device)\n","lstm_model.load_state_dict(torch.load(\"/content/drive/MyDrive/DL/FinalLSTM_model.pth\"))\n","lstm_model.eval()  # Set to evaluation mode\n","\n","# Load and preprocess the image\n","image_path = '/content/drive/MyDrive/Deep_learning/TrimDataset/Dataset/Validation/Fake/fake_2070.jpg'\n","image = Image.open(image_path).convert('RGB')\n","image = transform(image).unsqueeze(0).to(device)  # Add batch dimension and send to device\n","\n","# Step 1: Extract features using ResNet\n","with torch.no_grad():\n","    features = feature_extractor(image).unsqueeze(1)  # (batch, seq_len, features)\n","\n","# Step 2: Classify using the LSTM\n","with torch.no_grad():\n","    output = lstm_model(features)\n","    _, predicted = torch.max(output, 1)\n","\n","# Interpret the result\n","classes = {0: 'Real', 1: 'Fake'}\n","print(f\"Prediction: {classes[predicted.item()]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AIYMZfIA-VyA","executionInfo":{"status":"ok","timestamp":1730049720751,"user_tz":-330,"elapsed":1606,"user":{"displayName":"Bcuber Mem","userId":"09286632576840638536"}},"outputId":"ebe34dbc-e1ef-4242-e8dc-ae02db2cd958"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-22-b9ec7fc0d458>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  lstm_model.load_state_dict(torch.load(\"/content/drive/MyDrive/DL/FinalLSTM_model.pth\"))\n"]},{"output_type":"stream","name":"stdout","text":["Prediction: Real\n"]}]}]}